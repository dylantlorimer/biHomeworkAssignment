{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Lucid Software Business Intelligence Assignment\n",
    "\n",
    "For this assignment you will be interacting with public APIs and completing tasks using the data they provide. None of the questions are analytically challenging, most of the task is getting and processing the data from the APIs\n",
    "\n",
    "You should complete this assignmenet by yourself, but you may use any tools or resources at your disposal (e.g., internet, textbooks, spark, python, etc.). If you are using spark or python please use a ZEPL notebook. If you prefer another environment you may share your work once youâ€™ve completed the assignment.\n",
    "\n",
    "The assigned tasks should be ordered in increasing difficulty. Please complete as many as you can and use your own best judgement as you make decisions about how to interpret and model the data.\n",
    "\n",
    "When sharing your zepl workbook share it with zepl user jstark instead of over email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Earthquake Data\n",
    "https://earthquake.usgs.gov/fdsnws/event/1/\n",
    "\n",
    "How many earthquakes of at least 5 magnitude happened in and around Tonga in May of 2017?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the libraries necessary for the Earthquake Data and SpaceX Launch Data\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from urllib import *\n",
    "import urllib.request \n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize plotly and mapbox access\n",
    "plotly.tools.set_credentials_file(username='dylan.t.lorimer@gmail.com', api_key='gZQQodjxthmQnusI8HGD')\n",
    "mapbox_access_token = 'pk.eyJ1IjoiZGxvcmltZXIiLCJhIjoiY2pkbHY0b25zMGN2eTMzbzQ4ODdxeWE3YyJ9.CaSl5CksBlIL6fJOKY0kwA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read USGS earthquake data into a dataframe and filter for necessary rows and columns\n",
    "\n",
    "# Filtering for May 2017 earthquakes near Tonga (>=5.0 magnitude) is done in the url using the arguments: starttime, endtime, minmagnitude, longitude, latitude, maxradiuskm\n",
    "df = pd.read_csv(\"https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2017-05-01&endtime=2017-05-31&minmagnitude=5.0&longitude=-175.198&latitude=-21.179&maxradiuskm=1000\")\n",
    "df = df.query('type == \"earthquake\"')\n",
    "df1 = df[['time','place','mag','latitude','longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~dlorimer/5.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create interactive map for May 2017 Earthquakes of Magnitude 5.0 and Above, within 1000km of Tonga\n",
    "site_lat = df['latitude']\n",
    "site_lon = df['longitude']\n",
    "\n",
    "data = Data([\n",
    "    Scattermapbox(\n",
    "        lat=df['latitude'],\n",
    "        lon=df['longitude'],\n",
    "        mode='markers',\n",
    "        marker=Marker(\n",
    "            size=9\n",
    "        ),\n",
    "        text=df['place'] + '<br>Magnitude ' + (df['mag']).astype(str),\n",
    "    )]\n",
    ")\n",
    "        \n",
    "layout = Layout(\n",
    "    title='May 2017 Earthquakes of Magnitude 5.0 and Above, within 1000km of Tonga',\n",
    "    autosize=True,\n",
    "    hovermode='closest',\n",
    "    showlegend=False,\n",
    "    mapbox=dict(\n",
    "        accesstoken=mapbox_access_token,\n",
    "        bearing=0,\n",
    "        center=dict(lat=-21, lon=-175),\n",
    "        pitch=0,\n",
    "        zoom=3,\n",
    "        style='light'\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='May 2017 Earthquakes of Magnitude 5.0 and Above, within 1000km of Tonga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>place</th>\n",
       "      <th>mag</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-30T19:59:57.820Z</td>\n",
       "      <td>160km SSW of Nadi, Fiji</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-19.1606</td>\n",
       "      <td>176.8782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-26T06:27:30.540Z</td>\n",
       "      <td>42km S of Ndoi Island, Fiji</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-21.0360</td>\n",
       "      <td>-178.6770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05-25T06:02:20.140Z</td>\n",
       "      <td>169km SW of Vaini, Tonga</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-22.3132</td>\n",
       "      <td>-176.3299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-05-22T16:41:06.730Z</td>\n",
       "      <td>132km S of Hihifo, Tonga</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-17.1282</td>\n",
       "      <td>-173.5293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-16T15:29:14.480Z</td>\n",
       "      <td>South of the Fiji Islands</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-23.7723</td>\n",
       "      <td>-177.6057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-05-12T00:46:56.720Z</td>\n",
       "      <td>217km NE of Raoul Island, New Zealand</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-27.6765</td>\n",
       "      <td>-176.5945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-05-09T15:25:35.720Z</td>\n",
       "      <td>132km ESE of Pangai, Tonga</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-20.4035</td>\n",
       "      <td>-173.2567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-05-07T08:08:35.760Z</td>\n",
       "      <td>119km ESE of Neiafu, Tonga</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-18.8764</td>\n",
       "      <td>-172.8761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-05-02T14:07:00.240Z</td>\n",
       "      <td>South of Tonga</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-24.2588</td>\n",
       "      <td>-175.7662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time                                  place  mag  \\\n",
       "0  2017-05-30T19:59:57.820Z                160km SSW of Nadi, Fiji  5.0   \n",
       "1  2017-05-26T06:27:30.540Z            42km S of Ndoi Island, Fiji  5.0   \n",
       "2  2017-05-25T06:02:20.140Z               169km SW of Vaini, Tonga  5.6   \n",
       "3  2017-05-22T16:41:06.730Z               132km S of Hihifo, Tonga  5.3   \n",
       "4  2017-05-16T15:29:14.480Z              South of the Fiji Islands  5.1   \n",
       "5  2017-05-12T00:46:56.720Z  217km NE of Raoul Island, New Zealand  5.6   \n",
       "6  2017-05-09T15:25:35.720Z             132km ESE of Pangai, Tonga  5.1   \n",
       "7  2017-05-07T08:08:35.760Z             119km ESE of Neiafu, Tonga  5.0   \n",
       "8  2017-05-02T14:07:00.240Z                         South of Tonga  5.1   \n",
       "\n",
       "   latitude  longitude  \n",
       "0  -19.1606   176.8782  \n",
       "1  -21.0360  -178.6770  \n",
       "2  -22.3132  -176.3299  \n",
       "3  -17.1282  -173.5293  \n",
       "4  -23.7723  -177.6057  \n",
       "5  -27.6765  -176.5945  \n",
       "6  -20.4035  -173.2567  \n",
       "7  -18.8764  -172.8761  \n",
       "8  -24.2588  -175.7662  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print data table for earthquakes in map\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaceX Launch Data\n",
    "https://github.com/r-spacex/SpaceX-API/wiki/Past-Launches\n",
    "\n",
    "#### In which year did SpaceX first successfully reuse a capsule?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in SpaceX data and perform the first stage of JSON normalization\n",
    "with urllib.request.urlopen(\"https://api.spacexdata.com/v2/launches\") as url:\n",
    "    data = json.loads(url.read().decode())\n",
    "df_x = json_normalize(data=data)\n",
    "\n",
    "# rename a bunch of columns for clarity\n",
    "df_x.rename(columns={'launch_site.site_id':'launch_site_id',\n",
    "                     'launch_site.site_name':'launch_site_name',\n",
    "                     'launch_site.site_name_long':'launch_site_name_long',\n",
    "                     'rocket.rocket_id':'rocket_id',\n",
    "                     'rocket.rocket_name':'rocket_name',\n",
    "                     'rocket.rocket_type':'rocket_type',\n",
    "                     'links.mission_patch':'mission_patch',\n",
    "                     'links.reddit_campaign':'reddit_campaign',\n",
    "                     'links.reddit_launch':'reddit_launch',\n",
    "                     'links.reddit_recovery':'reddit_recovery',\n",
    "                     'links.reddit_media':'reddit_media',\n",
    "                     'links.presskit':'presskit',\n",
    "                     'links.article_link':'article_link',\n",
    "                     'links.video_link':'video_link'\n",
    "                    }, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>launch_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reuse.capsule</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              launch_year\n",
       "reuse.capsule            \n",
       "False                2006\n",
       "True                 2017"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the earliest year that a capsule was reused (True: 2017)\n",
    "pd.DataFrame(df_x.groupby(['reuse.capsule'], sort=False)['launch_year'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which flights used core Merlin 1C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the cores table\n",
    "\n",
    "# This table is a record of events associated with each core's flight, so\n",
    "# cores will appear multiple times. (I chose to give cores their own table to\n",
    "# answer the question quickly and so I didn't make the flights table too busy \n",
    "# later on)\n",
    "\n",
    "# Create a blank dataframe to populate \n",
    "cores_df = pd.DataFrame(columns=['core_serial', 'flight', 'land_success',\n",
    "       'landing_type', 'landing_vehicle', 'reused', 'rocket_id'])\n",
    "\n",
    "for i in range(len(df_x)):\n",
    "    row_cores = json_normalize(df_x['rocket.first_stage.cores'][i])\n",
    "    row_cores['flight_number'] = df_x['flight_number'][i]\n",
    "    row_cores['rocket_id'] = df_x['rocket_id'][i]\n",
    "    cores_df = pd.concat([cores_df, row_cores])\n",
    "\n",
    "# Clean up and clarify the table\n",
    "cores_df.rename(columns={'flight': 'flight_count'}, inplace=True) # now flight number represents the unique identifier for the flights and flight count represents the number of imes that the core has flown\n",
    "cores_df = cores_df.reset_index(drop=True)\n",
    "cores_df.drop(cores_df.columns[0],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight_number</th>\n",
       "      <th>core_serial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Merlin 1C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Merlin 1C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Merlin 1C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flight_number core_serial\n",
       "2            3.0   Merlin 1C\n",
       "3            4.0   Merlin 1C\n",
       "4            5.0   Merlin 1C"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the flights that used the 'Merlin 1C' core\n",
    "pd.DataFrame(cores_df[['flight_number','core_serial']][cores_df['core_serial'] == 'Merlin 1C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the past launch data into the following relational tables and document your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the payloads table\n",
    "\n",
    "# Create a blank dataframe to populate \n",
    "payloads_df = pd.DataFrame(columns=['cap_serial', 'cargo_manifest', 'customers', 'flight_number',\n",
    "       'flight_time_sec', 'mass_returned_kg', 'mass_returned_lbs', 'orbit',\n",
    "       'payload_id', 'payload_mass_kg', 'payload_mass_lbs', 'payload_type',\n",
    "       'reused', 'rocket_id'])\n",
    "\n",
    "for i in range(len(df_x)):\n",
    "    row_payloads = json_normalize(df_x['rocket.second_stage.payloads'][i])\n",
    "    row_payloads['flight_number'] = df_x['flight_number'][i]\n",
    "    row_payloads['rocket_id'] = df_x['rocket_id'][i]\n",
    "    payloads_df = pd.concat([payloads_df, row_payloads])\n",
    "\n",
    "# Reorganize columns\n",
    "payloads_df = payloads_df.reset_index(drop=True)\n",
    "payloads_cols = payloads_df.columns.tolist()\n",
    "payloads_cols = payloads_cols[8:9] + payloads_cols[3:4] + payloads_cols[-1:] + payloads_cols[0:2] + payloads_cols[4:7] + payloads_cols[9:12] + payloads_cols[7:8] + payloads_cols[2:3]\n",
    "payloads_df = payloads_df[payloads_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the flights table\n",
    "\n",
    "flights_df = df_x[['flight_number',\n",
    "                  'launch_date_utc', # took out other times because it's a simple transformation\n",
    "                  'launch_date_local',\n",
    "                  'rocket_id',\n",
    "                  'reuse.core',\n",
    "                  'reuse.side_core1',\n",
    "                  'reuse.side_core2',\n",
    "                  'reuse.fairings',\n",
    "                  'reuse.capsule',\n",
    "                  'telemetry.flight_club',\n",
    "                  'launch_site_id',\n",
    "                  'launch_success',\n",
    "                  'details']].copy()\n",
    "\n",
    "flights_df['details'] = flights_df['details'].str[:200]\n",
    "\n",
    "# Reorganize columns\n",
    "flights_cols = flights_df.columns.tolist()\n",
    "flights_cols = flights_cols[:1] + flights_cols[3:4] + flights_cols[1:3] + flights_cols[4:]\n",
    "flights_df = flights_df[flights_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the launch_sites table\n",
    "\n",
    "launch_sites_df = df_x[['launch_site_id', # moved these into their own dataframe because it was becoming an unwieldy table\n",
    "                  'launch_site_name',\n",
    "                  'launch_site_name_long']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the flight_links table\n",
    "\n",
    "# Again, to simplify the flights table for end users, I opted to create a\n",
    "# separate table for the flight links\n",
    "\n",
    "flight_links_df = df_x[['flight_number', # moved these into their own dataframe because it was becoming an unwieldy table\n",
    "                  'mission_patch',\n",
    "                  'reddit_campaign',\n",
    "                  'reddit_launch',\n",
    "                  'reddit_recovery',\n",
    "                  'reddit_media',\n",
    "                  'presskit',\n",
    "                  'article_link',\n",
    "                  'video_link']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build the rockets table\n",
    "\n",
    "rockets_df = df_x.groupby(['rocket_id',\n",
    "              'rocket_name',\n",
    "              'rocket_type'])['launch_date_utc'].min()\n",
    "rockets_df = rockets_df.reset_index()\n",
    "# Rename column for clarity\n",
    "rockets_df.rename(columns={'launch_date_utc':'type_effective_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the customers table\n",
    "\n",
    "# Get all customers for each row in payload_df's 'customers' column\n",
    "customers_df = payloads_df.set_index(['payload_id'])['customers'].apply(pd.Series).stack()\n",
    "customers_df = customers_df.reset_index()\n",
    "customers_df.columns = ['payload_id', 'customer_number','customer']\n",
    "customers_df.reset_index()\n",
    "customers_df['pc_id'] = range(1, len(customers_df) + 1)\n",
    "\n",
    "# Re-order the columns so they make a little more sense\n",
    "cols = customers_df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:1] + cols[2:] + cols[1:-1]\n",
    "customers_df = customers_df[cols]\n",
    "\n",
    "\n",
    "# Pull the customers column out of payload_df\n",
    "payloads_df = payloads_df.drop(['customers'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dfs = [cores_df, payloads_df, flights_df, launch_sites_df, flight_links_df, rockets_df, customers_df]\n",
    "df_names = ['x_cores', 'x_payloads', 'x_flights', 'x_launch_sites', 'x_flight_links', 'x_rockets', 'x_payload_customers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your Lucid Redshift user_id: dylan\n",
      "Input your Lucid Redshift password: 3sis=RLM\n"
     ]
    }
   ],
   "source": [
    "user_id = input(\"Input your Lucid Redshift user_id: \")\n",
    "password = input(\"Input your Lucid Redshift password: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_engine('postgresql://' + user_id + ':' + password + '@' + 'lucid-redshift-prod-enc.czguhkk4ukda.us-east-1.redshift.amazonaws.com:5439/lucid')\n",
    "\n",
    "for df in range(len(my_dfs)):\n",
    "    my_dfs[df].to_sql(df_names[df], conn, index = False, if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width: 640px; height: 480px; margin: 10px; position: relative;\"><iframe allowfullscreen frameborder=\"0\" style=\"width:640px; height:480px\" src=\"https://www.lucidchart.com/documents/embeddedchart/c5f1d96c-b41a-4000-b345-8d72130f8549\" id=\"Vkdf1x9IlxCA\"></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<div style=\"width: 640px; height: 480px; margin: 10px; position: relative;\"><iframe allowfullscreen frameborder=\"0\" style=\"width:640px; height:480px\" src=\"https://www.lucidchart.com/documents/embeddedchart/c5f1d96c-b41a-4000-b345-8d72130f8549\" id=\"Vkdf1x9IlxCA\"></iframe></div>'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
